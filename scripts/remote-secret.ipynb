{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a4f9afe",
   "metadata": {},
   "source": [
    "The following scripts intends to manually deploy required resources across different clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f816fa1d",
   "metadata": {},
   "source": [
    "# Remote Secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbee031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import subprocess\n",
    "import base64\n",
    "import sys\n",
    "import os\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "\n",
    "NAMES_FILE = \"names\"\n",
    "\n",
    "\n",
    "def read_pairs(filename: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"Read whitespace-separated pairs from filename. Skip empty/comment lines.\"\"\"\n",
    "    pairs: List[Tuple[str, str]] = []\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        for raw in f:\n",
    "            line = raw.strip()\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) < 2:\n",
    "                print(f\"Skipping malformed line (need at least 2 columns): {line}\", file=sys.stderr)\n",
    "                continue\n",
    "            # cluster name is first column, current secret context is second\n",
    "            pairs.append((parts[0], parts[1]))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def get_remote_secret_yaml(cluster_name: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Fetch the secret from the local cluster and return decoded YAML string found in\n",
    "    item[0].data[\"remote-secret.yaml\"].\n",
    "    Returns None if not found or on error.\n",
    "    \"\"\"\n",
    "    label = f\"skycluster.io/secret-type=cluster-cacert,skycluster.io/cluster-name={cluster_name}\"\n",
    "    cmd = [\"kubectl\", \"get\", \"secrets\", \"-n\", \"skycluster-system\", \"-l\", label, \"-o\", \"json\"]\n",
    "\n",
    "    try:\n",
    "        proc = subprocess.run(cmd, check=True, capture_output=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to run kubectl get for cluster '{cluster_name}': {e}\", file=sys.stderr)\n",
    "        print(e.stderr.decode(errors=\"ignore\"), file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        data = json.loads(proc.stdout)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Failed to parse kubectl JSON for cluster '{cluster_name}': {e}\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "    items = data.get(\"items\", [])\n",
    "    if not items:\n",
    "        print(f\"No secrets found for cluster '{cluster_name}' (label search).\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "    first = items[0]\n",
    "    secret_data = first.get(\"data\", {})\n",
    "    # The key used in the original jsonpath was remote-secret.yaml (with a dot).\n",
    "    key = \"remote-secret.yaml\"\n",
    "    if key not in secret_data:\n",
    "        # if not present, try to find any key that ends with 'remote-secret.yaml' or endswith '.yaml'\n",
    "        for k in secret_data.keys():\n",
    "            if k.endswith(\"remote-secret.yaml\") or k.endswith(\".yaml\"):\n",
    "                key = k\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Secret for cluster '{cluster_name}' does not contain 'remote-secret.yaml' in data keys: {list(secret_data.keys())}\", file=sys.stderr)\n",
    "            return None\n",
    "\n",
    "    b64val = secret_data.get(key)\n",
    "    if not b64val:\n",
    "        print(f\"No value for key '{key}' in secret for cluster '{cluster_name}'.\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        decoded = base64.b64decode(b64val).decode(\"utf-8\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to base64-decode remote secret for cluster '{cluster_name}': {e}\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "    return decoded\n",
    "\n",
    "\n",
    "def apply_secret_to_context(secret_yaml: str, context: str, KUBECONFIG_PATH: str) -> bool:\n",
    "    \"\"\"Apply the given YAML to the provided kubectl context. Returns True on success.\"\"\"\n",
    "    cmd = [\"kubectl\", \"--context\", context, \"apply\", \"-f\", \"-\"]\n",
    "    try:\n",
    "        env = os.environ.copy()\n",
    "        env[\"KUBECONFIG\"] = KUBECONFIG_PATH\n",
    "        proc = subprocess.run(cmd, input=secret_yaml.encode(\"utf-8\"), capture_output=True, check=True, env=env)\n",
    "        stdout = proc.stdout.decode(\"utf-8\", errors=\"ignore\").strip()\n",
    "        stderr = proc.stderr.decode(\"utf-8\", errors=\"ignore\").strip()\n",
    "        if stdout:\n",
    "            print(f\"[{context}] apply stdout:\\n{stdout}\")\n",
    "        if stderr:\n",
    "            print(f\"[{context}] apply stderr:\\n{stderr}\", file=sys.stderr)\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"[{context}] Failed to apply secret: returncode={e.returncode}\", file=sys.stderr)\n",
    "        if e.stdout:\n",
    "            print(e.stdout.decode(errors=\"ignore\"), file=sys.stderr)\n",
    "        if e.stderr:\n",
    "            print(e.stderr.decode(errors=\"ignore\"), file=sys.stderr)\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe584b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# k get xkubes.bm | tail -n+2 | awk '{print $1}' > names\n",
    "# k get xkubes.os | tail -n+2 | awk '{print $1}' >> names\n",
    "# k get xkubes.aws | tail -n+2 | awk '{print $1}' >> names\n",
    "# k get xkubes.gcp | tail -n+2 | awk '{print $1}' >> names\n",
    "# echo \"\" > ctxs\n",
    "# k config get-contexts | tail -n+2  >> ctxs\n",
    "\n",
    "# rm ctxs_to_use\n",
    "# while read r; do cat ./ctxs | grep \"${r::-6}\" | awk '{print $1}' >> ctxs_to_use;done < names\n",
    "\n",
    "# # open ctx_to_use and match wuth names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c1d678",
   "metadata": {},
   "outputs": [],
   "source": [
    "KUBECONFIG_PATH=\"/home/ubuntu/.kube/config:/tmp/kubeconfigs/kube-savi-toronto:/tmp/kubeconfigs/xk-aws-us-west--hxvbe:/tmp/kubeconfigs/xk-aws-eu-west--q28fg:/tmp/kubeconfigs/xk-aws-ap-east--12z23:/tmp/kubeconfigs/xk-aws-eu-north-6kfjn:/tmp/kubeconfigs/xk-aws-ap-north-8db1e:/tmp/kubeconfigs/xk-aws-us-east--us9a8:/tmp/kubeconfigs/xk-aws-ca-centr-gsa09:/tmp/kubeconfigs/xk-gcp-us-south-v2dvh:/tmp/kubeconfigs/xk-gcp-northame-oo44n:/tmp/kubeconfigs/xk-aws-eu-south-66hap:/tmp/kubeconfigs/kube-os-scinet:/tmp/kubeconfigs/xk-gcp-us-centr-e3d7y:/tmp/kubeconfigs/xk-gcp-us-east1-ny5jh:/tmp/kubeconfigs/xk-aws-ca-west--vzd0n:/tmp/kubeconfigs/xk-aws-us-east--guz6u:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d79bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NAMES_FILE=\"remote-names\"\n",
    "pairs = read_pairs(NAMES_FILE)\n",
    "if not pairs:\n",
    "    print(f\"No valid pairs read from {NAMES_FILE}. Exiting.\", file=sys.stderr)\n",
    "    sys.exit(1)\n",
    "\n",
    "# Build list of all contexts (the second column values)\n",
    "all_contexts = [ctx for (_cluster, ctx) in pairs]\n",
    "\n",
    "# For each pair, get the secret and apply to all other contexts (except itself)\n",
    "for cluster_name, source_ctx in pairs:\n",
    "    print(f\"Processing cluster '{cluster_name}' (source context: '{source_ctx}')\")\n",
    "    secret_yaml = get_remote_secret_yaml(cluster_name)\n",
    "    if not secret_yaml:\n",
    "        print(f\"Skipping cluster '{cluster_name}' due to missing secret.\", file=sys.stderr)\n",
    "        continue\n",
    "\n",
    "    # apply to every context except source_ctx\n",
    "    targets = [c for c in all_contexts if c != source_ctx]\n",
    "    if not targets:\n",
    "        print(f\"No target contexts to apply for cluster '{cluster_name}'.\")\n",
    "        continue\n",
    "\n",
    "    for target_ctx in targets:\n",
    "        print(f\"Applying secret from cluster '{cluster_name}' to context '{target_ctx}'...\")\n",
    "        ok = apply_secret_to_context(secret_yaml, target_ctx, KUBECONFIG_PATH)\n",
    "        if ok:\n",
    "            print(f\"Applied to {target_ctx}\")\n",
    "        else:\n",
    "            print(f\"Failed to apply to {target_ctx}\", file=sys.stderr)\n",
    "    # break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfac0e29",
   "metadata": {},
   "source": [
    "# Application Manifests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eb7c50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "import tempfile\n",
    "from typing import Dict, Iterable, Optional, Tuple\n",
    "\n",
    "\n",
    "try:\n",
    "    import yaml\n",
    "except Exception:\n",
    "    print(\"ERROR: PyYAML is required. Install with: pip install pyyaml\")\n",
    "    sys.exit(2)\n",
    "\n",
    "\n",
    "\n",
    "def ask_for_path(prompt, default):\n",
    "    if os.path.exists(default):\n",
    "        return default\n",
    "    path = input(f\"{prompt} (default: {default}): \").strip()\n",
    "    if not path:\n",
    "        path = default\n",
    "    return path\n",
    "\n",
    "\n",
    "def read_wrapper_yaml(path):\n",
    "    \"\"\"Read the YAML wrapper file and return a dict with 'manifest' and 'provider' keys.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Input YAML file not found: {path}\")\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    if not isinstance(data, dict):\n",
    "        raise ValueError(\"Input YAML does not contain a mapping at top level.\")\n",
    "    if \"manifest\" not in data or \"provider\" not in data:\n",
    "        raise KeyError(\"Input YAML must contain top-level keys 'manifest' and 'provider'.\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_mapping_file(path):\n",
    "    \"\"\"Load mapping file where each non-empty non-comment line is:\n",
    "       provider_key <whitespace> context_name\n",
    "       Returns dict mapping provider_key -> context_name\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Mapping file not found: {path}\")\n",
    "    mapping = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for raw in f:\n",
    "            line = raw.strip()\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            key = parts[0]\n",
    "            context = parts[1]\n",
    "            mapping[key] = context\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def strip_provider_prefix(provider_raw, prefix=\"k8s-eks-\"):\n",
    "    \"\"\"Remove prefix (only once) if present.\"\"\"\n",
    "    if provider_raw.startswith(prefix):\n",
    "        return provider_raw[len(prefix) :]\n",
    "    if provider_raw.startswith(\"k8s-gke-\"):\n",
    "        return provider_raw[len(\"k8s-gke-\") :]\n",
    "    return provider_raw\n",
    "\n",
    "\n",
    "def find_context_for_provider(provider_key, mapping):\n",
    "    \"\"\"Return context name for the provider_key or None if not found.\"\"\"\n",
    "    # if key contains the provider_key as substring of any mapping key, return that context\n",
    "    for key, context in mapping.items():\n",
    "        if provider_key in key or key in provider_key:\n",
    "            return context\n",
    "\n",
    "\n",
    "def write_manifest_to_tempfile(manifest_obj):\n",
    "    \"\"\"Dump the manifest object to a temporary YAML file and return its path.\"\"\"\n",
    "    fd, path = tempfile.mkstemp(prefix=\"manifest_\", suffix=\".yaml\")\n",
    "    os.close(fd)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        yaml.safe_dump(manifest_obj, f, default_flow_style=False)\n",
    "    return path\n",
    "\n",
    "\n",
    "def run_kubectl_apply(manifest_path, context):\n",
    "    \"\"\"Run kubectl apply -f manifest_path --context context. Returns (returncode, stdout, stderr).\"\"\"\n",
    "    kubectl_path = shutil.which(\"kubectl\")\n",
    "    if not kubectl_path:\n",
    "        raise EnvironmentError(\"kubectl not found in PATH. Please install or add it to PATH.\")\n",
    "    env = os.environ.copy()\n",
    "    env[\"KUBECONFIG\"] = KUBECONFIG_PATH\n",
    "    cmd = [kubectl_path, \"apply\", \"-f\", manifest_path, \"--context\", context]\n",
    "    proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, env=env)\n",
    "    return proc.returncode, proc.stdout, proc.stderr\n",
    "\n",
    "\n",
    "\n",
    "def run_shell_command(command: str, kubeconfig_path: Optional[str] = None) -> Tuple[int, str, str]:\n",
    "    \"\"\"\n",
    "    Run a given shell command string and return (returncode, stdout, stderr).\n",
    "    If kubeconfig_path is provided, set KUBECONFIG in the environment for the subprocess.\n",
    "    \"\"\"\n",
    "    env = os.environ.copy()\n",
    "    env[\"KUBECONFIG\"] = KUBECONFIG_PATH\n",
    "\n",
    "    proc = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, env=env)\n",
    "    return proc.returncode, proc.stdout, proc.stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5363c7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "KUBECONFIG_PATH=\"/home/ubuntu/.kube/config:/tmp/kubeconfigs/kube-savi-toronto:/tmp/kubeconfigs/xk-aws-us-west--hxvbe:/tmp/kubeconfigs/xk-aws-eu-west--q28fg:/tmp/kubeconfigs/xk-aws-ap-east--12z23:/tmp/kubeconfigs/xk-aws-eu-north-6kfjn:/tmp/kubeconfigs/xk-aws-ap-north-8db1e:/tmp/kubeconfigs/xk-aws-us-east--us9a8:/tmp/kubeconfigs/xk-aws-ca-centr-gsa09:/tmp/kubeconfigs/xk-gcp-us-south-v2dvh:/tmp/kubeconfigs/xk-gcp-northame-oo44n:/tmp/kubeconfigs/xk-aws-eu-south-66hap:/tmp/kubeconfigs/kube-os-scinet:/tmp/kubeconfigs/xk-gcp-us-centr-e3d7y:/tmp/kubeconfigs/xk-gcp-us-east1-ny5jh:/tmp/kubeconfigs/xk-aws-ca-west--vzd0n:/tmp/kubeconfigs/xk-aws-us-east--guz6u:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bdc92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_files = \"\"\"\n",
    "ns-air-quality-aws-a-1vt76.yaml\n",
    "ns-air-quality-aws-a-ycn90.yaml\n",
    "ns-air-quality-aws-c-2qm6v.yaml\n",
    "ns-air-quality-aws-c-n0td4.yaml\n",
    "ns-air-quality-aws-e-9j20v.yaml\n",
    "ns-air-quality-aws-e-dpc4q.yaml\n",
    "ns-air-quality-aws-e-k5n1b.yaml\n",
    "ns-air-quality-aws-u-h6o7e.yaml\n",
    "ns-air-quality-aws-u-manuj.yaml\n",
    "ns-air-quality-aws-u-nh5wp.yaml\n",
    "ns-air-quality-gcp-n-fmk7f.yaml\n",
    "ns-air-quality-gcp-u-a5sym.yaml\n",
    "ns-air-quality-gcp-u-aebmn.yaml\n",
    "ns-air-quality-gcp-u-enttq.yaml\n",
    "ns-air-quality-savi--2njba.yaml\n",
    "ns-air-quality-savi--xhz29.yaml\n",
    "ns-air-quality-savi--zco7a.yaml\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "65495da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_files = \"\"\"\n",
    "dp-central-storage-a-gryxc.yaml\n",
    "dp-collector-aws-ap--p2ynz.yaml\n",
    "dp-collector-aws-ap--wqmka.yaml\n",
    "dp-collector-aws-ca--2mb6p.yaml\n",
    "dp-collector-aws-ca--ctn77.yaml\n",
    "dp-collector-aws-eu--5y9cf.yaml\n",
    "dp-collector-aws-eu--fq8lu.yaml\n",
    "dp-collector-aws-eu--vnspi.yaml\n",
    "dp-collector-aws-us--7tdxm.yaml\n",
    "dp-collector-aws-us--tdliz.yaml\n",
    "dp-collector-edge-sa-38uuj.yaml\n",
    "dp-collector-edge-sa-9wny2.yaml\n",
    "dp-collector-edge-sa-b8y89.yaml\n",
    "dp-collector-gcp-nor-1cvu9.yaml\n",
    "dp-collector-gcp-us--7bk5c.yaml\n",
    "dp-collector-gcp-us--7yfyu.yaml\n",
    "dp-collector-gcp-us--dsgj8.yaml\n",
    "dp-dashboard-aws-us--l6xhn.yaml\n",
    "dp-ingestor-aws-ap-e-620al.yaml\n",
    "dp-ingestor-aws-ap-n-6nn4x.yaml\n",
    "dp-ingestor-aws-ca-c-vaqtz.yaml\n",
    "dp-ingestor-aws-ca-w-tpeln.yaml\n",
    "dp-ingestor-aws-eu-s-bf280.yaml\n",
    "dp-ingestor-aws-eu-w-vrr4k.yaml\n",
    "dp-ingestor-aws-us-e-agldo.yaml\n",
    "dp-ingestor-aws-us-e-zxtla.yaml\n",
    "dp-ingestor-aws-us-w-a1gb7.yaml\n",
    "dp-ingestor-gcp-nort-2ee9p.yaml\n",
    "dp-ingestor-gcp-us-e-pulmr.yaml\n",
    "dp-local-storage-aws-7hp1a.yaml\n",
    "dp-local-storage-aws-7xr5k.yaml\n",
    "dp-local-storage-aws-cqu8z.yaml\n",
    "dp-local-storage-aws-jot81.yaml\n",
    "dp-local-storage-aws-zf5en.yaml\n",
    "dp-processor-aws-ap--960qj.yaml\n",
    "dp-processor-aws-ca--pf5q4.yaml\n",
    "dp-processor-aws-eu--e5dxo.yaml\n",
    "dp-processor-aws-us--54gen.yaml\n",
    "dp-processor-aws-us--fhp6d.yaml\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfbb8aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_files = \"\"\"\n",
    "svc-svc-central-stor-0dsqw.yaml\n",
    "svc-svc-central-stor-41j5u.yaml\n",
    "svc-svc-central-stor-6uqfv.yaml\n",
    "svc-svc-central-stor-74tu5.yaml\n",
    "svc-svc-central-stor-7kaz9.yaml\n",
    "svc-svc-central-stor-7zxmj.yaml\n",
    "svc-svc-central-stor-8mukb.yaml\n",
    "svc-svc-central-stor-b18o1.yaml\n",
    "svc-svc-central-stor-e8coi.yaml\n",
    "svc-svc-central-stor-htcqg.yaml\n",
    "svc-svc-central-stor-j9fqr.yaml\n",
    "svc-svc-central-stor-k6tds.yaml\n",
    "svc-svc-central-stor-lv57r.yaml\n",
    "svc-svc-central-stor-n1dv9.yaml\n",
    "svc-svc-central-stor-v3wbv.yaml\n",
    "svc-svc-central-stor-vujao.yaml\n",
    "svc-svc-central-stor-zg4o9.yaml\n",
    "svc-svc-collector-aw-0fk2e.yaml\n",
    "svc-svc-collector-aw-3fzyy.yaml\n",
    "svc-svc-collector-aw-dcm11.yaml\n",
    "svc-svc-collector-aw-jhchg.yaml\n",
    "svc-svc-collector-aw-k71vm.yaml\n",
    "svc-svc-collector-aw-m0p4a.yaml\n",
    "svc-svc-collector-aw-oogxe.yaml\n",
    "svc-svc-collector-aw-u2uab.yaml\n",
    "svc-svc-collector-aw-wqtjh.yaml\n",
    "svc-svc-collector-aw-yjb4b.yaml\n",
    "svc-svc-collector-gc-7m3rl.yaml\n",
    "svc-svc-collector-gc-jfd99.yaml\n",
    "svc-svc-collector-gc-tfvaj.yaml\n",
    "svc-svc-collector-gc-z9fza.yaml\n",
    "svc-svc-collector-sa-7acvt.yaml\n",
    "svc-svc-collector-sa-hqeie.yaml\n",
    "svc-svc-collector-sa-ug79r.yaml\n",
    "svc-svc-dashboard-aw-4ngk9.yaml\n",
    "svc-svc-dashboard-aw-albid.yaml\n",
    "svc-svc-dashboard-aw-g46k2.yaml\n",
    "svc-svc-dashboard-aw-ivnfl.yaml\n",
    "svc-svc-dashboard-aw-lebcl.yaml\n",
    "svc-svc-dashboard-aw-qg9nf.yaml\n",
    "svc-svc-dashboard-aw-t6s1o.yaml\n",
    "svc-svc-dashboard-aw-tis3x.yaml\n",
    "svc-svc-dashboard-aw-wck6f.yaml\n",
    "svc-svc-dashboard-aw-zh5cx.yaml\n",
    "svc-svc-dashboard-gc-mtllc.yaml\n",
    "svc-svc-dashboard-gc-ntufx.yaml\n",
    "svc-svc-dashboard-gc-sg07v.yaml\n",
    "svc-svc-dashboard-gc-syelr.yaml\n",
    "svc-svc-dashboard-sa-2azkg.yaml\n",
    "svc-svc-dashboard-sa-crf20.yaml\n",
    "svc-svc-dashboard-sa-d2pjb.yaml\n",
    "svc-svc-ingestor-aws-16clc.yaml\n",
    "svc-svc-ingestor-aws-60wgn.yaml\n",
    "svc-svc-ingestor-aws-8sjh5.yaml\n",
    "svc-svc-ingestor-aws-buv19.yaml\n",
    "svc-svc-ingestor-aws-jym63.yaml\n",
    "svc-svc-ingestor-aws-p0t0l.yaml\n",
    "svc-svc-ingestor-aws-rzryr.yaml\n",
    "svc-svc-ingestor-aws-vua9z.yaml\n",
    "svc-svc-ingestor-aws-x4zde.yaml\n",
    "svc-svc-ingestor-aws-yiv72.yaml\n",
    "svc-svc-ingestor-gcp-2swcw.yaml\n",
    "svc-svc-ingestor-gcp-6xqfz.yaml\n",
    "svc-svc-ingestor-gcp-mwnet.yaml\n",
    "svc-svc-ingestor-gcp-sipkh.yaml\n",
    "svc-svc-ingestor-sav-iguu1.yaml\n",
    "svc-svc-ingestor-sav-xt4p3.yaml\n",
    "svc-svc-ingestor-sav-zo4g1.yaml\n",
    "svc-svc-local-storag-2wx4q.yaml\n",
    "svc-svc-local-storag-3duk2.yaml\n",
    "svc-svc-local-storag-4f20r.yaml\n",
    "svc-svc-local-storag-4zlpt.yaml\n",
    "svc-svc-local-storag-5cbh7.yaml\n",
    "svc-svc-local-storag-6i1qe.yaml\n",
    "svc-svc-local-storag-8s34h.yaml\n",
    "svc-svc-local-storag-9vauu.yaml\n",
    "svc-svc-local-storag-ag0uh.yaml\n",
    "svc-svc-local-storag-lq8ft.yaml\n",
    "svc-svc-local-storag-m6zn1.yaml\n",
    "svc-svc-local-storag-pffww.yaml\n",
    "svc-svc-local-storag-qcedr.yaml\n",
    "svc-svc-local-storag-rmy4p.yaml\n",
    "svc-svc-local-storag-tv4ni.yaml\n",
    "svc-svc-local-storag-xv6ot.yaml\n",
    "svc-svc-local-storag-z1j4w.yaml\n",
    "svc-svc-processor-aw-1gtfu.yaml\n",
    "svc-svc-processor-aw-3gg4q.yaml\n",
    "svc-svc-processor-aw-6a7p6.yaml\n",
    "svc-svc-processor-aw-6mj0c.yaml\n",
    "svc-svc-processor-aw-a18iu.yaml\n",
    "svc-svc-processor-aw-begx7.yaml\n",
    "svc-svc-processor-aw-bjvhu.yaml\n",
    "svc-svc-processor-aw-lnrqv.yaml\n",
    "svc-svc-processor-aw-yl952.yaml\n",
    "svc-svc-processor-aw-zog21.yaml\n",
    "svc-svc-processor-gc-f911q.yaml\n",
    "svc-svc-processor-gc-spwcw.yaml\n",
    "svc-svc-processor-gc-vzdm9.yaml\n",
    "svc-svc-processor-gc-wu5uj.yaml\n",
    "svc-svc-processor-sa-0ae54.yaml\n",
    "svc-svc-processor-sa-4xmi3.yaml\n",
    "svc-svc-processor-sa-q8f4c.yaml\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2256d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_svc_files=\"\"\"\n",
    "vs-svc-central-storage-aw-3in6k.yaml\n",
    "vs-svc-central-storage-aw-ax5oo.yaml\n",
    "vs-svc-central-storage-aw-cy32m.yaml\n",
    "vs-svc-central-storage-aw-faal4.yaml\n",
    "vs-svc-central-storage-aw-ujbm8.yaml\n",
    "vs-svc-ingestor-aws-ap-ea-p6ir7.yaml\n",
    "vs-svc-ingestor-aws-ap-no-a57sw.yaml\n",
    "vs-svc-ingestor-aws-ca-ce-lfv91.yaml\n",
    "vs-svc-ingestor-aws-ca-we-z8lo7.yaml\n",
    "vs-svc-ingestor-aws-eu-no-ttc37.yaml\n",
    "vs-svc-ingestor-aws-eu-so-0bfbn.yaml\n",
    "vs-svc-ingestor-aws-eu-we-s8h9l.yaml\n",
    "vs-svc-ingestor-aws-us-ea-ysjxi.yaml\n",
    "vs-svc-ingestor-aws-us-we-watsq.yaml\n",
    "vs-svc-ingestor-gcp-north-5lqv2.yaml\n",
    "vs-svc-ingestor-gcp-us-ce-49hm2.yaml\n",
    "vs-svc-ingestor-gcp-us-ea-fhh6x.yaml\n",
    "vs-svc-ingestor-gcp-us-so-v2tda.yaml\n",
    "vs-svc-ingestor-savi-scin-ftc5x.yaml\n",
    "vs-svc-ingestor-savi-toro-zsd24.yaml\n",
    "vs-svc-ingestor-savi-vaug-8h96n.yaml\n",
    "vs-svc-local-storage-aws--959gp.yaml\n",
    "vs-svc-local-storage-aws--9g9fw.yaml\n",
    "vs-svc-local-storage-aws--c382g.yaml\n",
    "vs-svc-local-storage-aws--cv7vx.yaml\n",
    "vs-svc-local-storage-aws--ejpt8.yaml\n",
    "vs-svc-local-storage-aws--ghi02.yaml\n",
    "vs-svc-local-storage-aws--iw2df.yaml\n",
    "vs-svc-local-storage-aws--p4mgr.yaml\n",
    "vs-svc-local-storage-aws--r3eey.yaml\n",
    "vs-svc-local-storage-gcp--7nik8.yaml\n",
    "vs-svc-local-storage-gcp--ea3zt.yaml\n",
    "vs-svc-processor-aws-ap-n-pvo0f.yaml\n",
    "vs-svc-processor-aws-ca-c-n9ebh.yaml\n",
    "vs-svc-processor-aws-eu-w-94rkr.yaml\n",
    "vs-svc-processor-aws-us-e-6hahw.yaml\n",
    "vs-svc-processor-aws-us-w-k366u.yaml\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a18f48aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_files = \"\"\"\n",
    "dr-svc-central-storage-aw-1kyon.yaml\n",
    "dr-svc-central-storage-aw-ha9h8.yaml\n",
    "dr-svc-central-storage-aw-pczdt.yaml\n",
    "dr-svc-central-storage-aw-sbb2p.yaml\n",
    "dr-svc-central-storage-aw-t7sdr.yaml\n",
    "dr-svc-ingestor-aws-ap-ea-mgxlo.yaml\n",
    "dr-svc-ingestor-aws-ap-no-9iier.yaml\n",
    "dr-svc-ingestor-aws-ca-ce-fkoqe.yaml\n",
    "dr-svc-ingestor-aws-ca-we-m64z1.yaml\n",
    "dr-svc-ingestor-aws-eu-no-zjkez.yaml\n",
    "dr-svc-ingestor-aws-eu-so-6yk85.yaml\n",
    "dr-svc-ingestor-aws-eu-we-azlrz.yaml\n",
    "dr-svc-ingestor-aws-us-ea-dafxd.yaml\n",
    "dr-svc-ingestor-aws-us-we-49fks.yaml\n",
    "dr-svc-ingestor-gcp-north-3cifk.yaml\n",
    "dr-svc-ingestor-gcp-us-ce-y195j.yaml\n",
    "dr-svc-ingestor-gcp-us-ea-t7mlm.yaml\n",
    "dr-svc-ingestor-gcp-us-so-isf5s.yaml\n",
    "dr-svc-ingestor-savi-scin-n3zt9.yaml\n",
    "dr-svc-ingestor-savi-toro-bxvca.yaml\n",
    "dr-svc-ingestor-savi-vaug-aafqa.yaml\n",
    "dr-svc-local-storage-aws--1o8au.yaml\n",
    "dr-svc-local-storage-aws--2z0yl.yaml\n",
    "dr-svc-local-storage-aws--jp4jc.yaml\n",
    "dr-svc-local-storage-aws--odby0.yaml\n",
    "dr-svc-local-storage-aws--ofols.yaml\n",
    "dr-svc-local-storage-aws--rv9op.yaml\n",
    "dr-svc-local-storage-aws--sfapx.yaml\n",
    "dr-svc-local-storage-aws--uoul7.yaml\n",
    "dr-svc-local-storage-aws--wv25c.yaml\n",
    "dr-svc-local-storage-gcp--gp6ym.yaml\n",
    "dr-svc-local-storage-gcp--m13wk.yaml\n",
    "dr-svc-processor-aws-ap-n-ihfer.yaml\n",
    "dr-svc-processor-aws-ca-c-2jhzj.yaml\n",
    "dr-svc-processor-aws-eu-w-ipy3z.yaml\n",
    "dr-svc-processor-aws-us-e-hg41m.yaml\n",
    "dr-svc-processor-aws-us-w-jn9ez.yaml\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "22793ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = dr_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "434a5705",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = \"\"\"\n",
    "dp-ingestor-aws-ap-e-620al.yaml\n",
    "dp-ingestor-aws-ap-n-6nn4x.yaml\n",
    "dp-ingestor-aws-ca-c-vaqtz.yaml\n",
    "dp-ingestor-aws-ca-w-tpeln.yaml\n",
    "dp-ingestor-aws-eu-s-bf280.yaml\n",
    "dp-ingestor-aws-eu-w-vrr4k.yaml\n",
    "dp-ingestor-aws-us-e-agldo.yaml\n",
    "dp-ingestor-aws-us-e-zxtla.yaml\n",
    "dp-ingestor-aws-us-w-a1gb7.yaml\n",
    "dp-ingestor-gcp-nort-2ee9p.yaml\n",
    "dp-ingestor-gcp-us-e-pulmr.yaml\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdc3a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder = \"/tmp/istio2/\"\n",
    "mapping_path = \"remote-names\"\n",
    "\n",
    "filenames = [ln.strip() for ln in input_files.splitlines() if ln.strip()]\n",
    "for fname in filenames:\n",
    "    full_path = os.path.join(folder, fname)\n",
    "    data = read_wrapper_yaml(full_path)\n",
    "    manifest_obj = data[\"manifest\"]\n",
    "    provider_raw = str(data[\"provider\"]).strip()\n",
    "    print(provider_raw)\n",
    "    if provider_raw == \"\":\n",
    "        continue\n",
    "\n",
    "    provider_key = strip_provider_prefix(provider_raw, prefix=\"k8s-eks-\")\n",
    "    provider_key = provider_key[:-6]\n",
    "    print(f\"Using provider key (prefix stripped): {provider_key}\")\n",
    "\n",
    "    mapping = load_mapping_file(mapping_path)\n",
    "\n",
    "    context = find_context_for_provider(provider_key, mapping)\n",
    "    print(f\"Resolved kubectl context: {context}\")\n",
    "    if context is None:\n",
    "        print(f\" ==> Could not find context for provider key '{provider_key}'. Skipping.\", file=sys.stderr)\n",
    "        continue\n",
    "\n",
    "    tmp_manifest = write_manifest_to_tempfile(manifest_obj)\n",
    "\n",
    "    code, out, err = run_kubectl_apply(tmp_manifest, context)\n",
    "    print(out.strip())\n",
    "    print(err.strip())\n",
    "    print(\"----------\")\n",
    "    \n",
    "    if code != 0:\n",
    "        print(f\"kubectl exited with code {code}\")\n",
    "        sys.exit(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1813063",
   "metadata": {},
   "source": [
    "# Kiali Remote Secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab654cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# kube-os-scinet-hxn2s        br2\n",
    "CTX_NAME = \"\"\"\n",
    "kube-savi-toronto-hc4cq        op1\n",
    "xk-aws-ap-east--12z23        aws3\n",
    "xk-aws-ap-north-8db1e        aws4\n",
    "xk-aws-ca-centr-gsa09        aws5\n",
    "xk-aws-ca-west--vzd0n        aws6\n",
    "xk-aws-eu-north-6kfjn        aws7\n",
    "xk-aws-eu-south-66hap        aws8\n",
    "xk-aws-eu-west--q28fg        aws9\n",
    "xk-aws-us-east--guz6u        aws10\n",
    "xk-aws-us-east--us9a8        aws11\n",
    "xk-aws-us-west--hxvbe        aws12\n",
    "xk-gcp-northame-oo44n-77zlf        gcp1\n",
    "xk-gcp-us-centr-e3d7y-jsctz        gcp2\n",
    "xk-gcp-us-east1-ny5jh-9q5ff        gcp3\n",
    "xk-gcp-us-south-v2dvh-cvvqm        gcp4\n",
    "\"\"\"\n",
    "\n",
    "# parse into (context, cluster_name) pairs\n",
    "lines = [ln.strip() for ln in CTX_NAME.splitlines() if ln.strip()]\n",
    "ctx_pairs = [tuple(ln.split(None, 1)) for ln in lines]  # (context, cluster_name)\n",
    "\n",
    "kiali_remote = \"/home/ubuntu/kiali-prepare-remote-cluster.sh\"\n",
    "\n",
    "def install(name, cluster_name):\n",
    "    cmd = (\n",
    "        f\"{kiali_remote} --remote-cluster-name {cluster_name} \"\n",
    "        f\"--process-remote-resources true \"\n",
    "        f\"--process-kiali-secret true \"\n",
    "        f\"--kiali-cluster-namespace istio-system \"\n",
    "        f\"--kiali-cluster-context kind-skycluster  --remote-cluster-context {name} \"\n",
    "    )\n",
    "    try:\n",
    "        code, out, err = run_shell_command(cmd, kubeconfig_path=KUBECONFIG_PATH)\n",
    "    except Exception as e:\n",
    "        return {\"name\": name, \"cluster\": cluster_name, \"code\": -1, \"out\": \"\", \"err\": str(e)}\n",
    "    return {\"name\": name, \"cluster\": cluster_name, \"code\": code, \"out\": out, \"err\": err}\n",
    "\n",
    "max_workers = min(10, len(ctx_pairs))\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as exe:\n",
    "    futures = {exe.submit(install, ctx_name, cluster_name): (ctx_name, cluster_name)\n",
    "               for cluster_name, ctx_name in ctx_pairs}\n",
    "    for fut in as_completed(futures):\n",
    "        res = fut.result()\n",
    "        print(f\"Installing remote-secret kiali in context: {res['name']} (cluster: {res['cluster']})\")\n",
    "        print(\"return code:\", res[\"code\"])\n",
    "        print(res[\"out\"])\n",
    "        print(res[\"err\"])\n",
    "        print(\"------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41116a1",
   "metadata": {},
   "source": [
    "# Helm Prometheus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6a19cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "CONTEXTS=\"\"\"\n",
    "aws3\n",
    "aws4\n",
    "aws5\n",
    "aws6\n",
    "aws7\n",
    "aws8\n",
    "aws9\n",
    "aws10\n",
    "aws11\n",
    "aws12\n",
    "gcp1\n",
    "gcp2\n",
    "gcp3\n",
    "gcp4\n",
    "op1\n",
    "\"\"\"\n",
    "\n",
    "ctx = [ln.strip() for ln in CONTEXTS.splitlines() if ln.strip()]\n",
    "prom_values_file = \"/home/ubuntu/skycluster-project/skycluster-operator/examples/dev/prometheus/prometheous-thanos-values.yaml\"\n",
    "\n",
    "\n",
    "def install(name):\n",
    "    cmd = (\n",
    "        f\"helm install {name} prometheus-community/kube-prometheus-stack \"\n",
    "        f\"-f {prom_values_file} -n monitoring \"\n",
    "        f\"--create-namespace --kube-context {name}\"\n",
    "    )\n",
    "    try:\n",
    "        code, out, err = run_shell_command(cmd, kubeconfig_path=KUBECONFIG_PATH)\n",
    "    except Exception as e:\n",
    "        return {\"name\": name, \"code\": -1, \"out\": \"\", \"err\": str(e)}\n",
    "    return {\"name\": name, \"code\": code, \"out\": out, \"err\": err}\n",
    "\n",
    "\n",
    "max_workers = min(10, len(ctx))  # tune as needed\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as exe:\n",
    "    futures = {exe.submit(install, name): name for name in ctx}\n",
    "    for fut in as_completed(futures):\n",
    "        res = fut.result()\n",
    "        print(f\"Installing prometheus-thanos in context: {res['name']}\")\n",
    "        print(\"return code:\", res[\"code\"])\n",
    "        print(res[\"out\"])\n",
    "        print(res[\"err\"])\n",
    "        print(\"------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0704573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CONTEXTS=\"\"\"\n",
    "aws3\n",
    "aws4\n",
    "aws5\n",
    "aws6\n",
    "aws7\n",
    "aws8\n",
    "aws9\n",
    "aws10\n",
    "aws11\n",
    "aws12\n",
    "gcp1\n",
    "gcp2\n",
    "gcp3\n",
    "gcp4\n",
    "op1\n",
    "\"\"\"\n",
    "\n",
    "ctx = [ln.strip() for ln in CONTEXTS.splitlines() if ln.strip()]\n",
    "\n",
    "def run_this(name):\n",
    "    cmd = (\n",
    "        f\"kubectl --context {name} get svc {name}-kube-prometheus-stack-thanos-external -n monitoring \"\n",
    "        f\"-o jsonpath='{{.spec.clusterIP}}'\"\n",
    "    )\n",
    "    try:\n",
    "        code, out, err = run_shell_command(cmd, kubeconfig_path=KUBECONFIG_PATH)\n",
    "    except Exception as e:\n",
    "        return {\"name\": name, \"code\": -1, \"out\": \"\", \"err\": str(e)}\n",
    "    return {\"name\": name, \"code\": code, \"out\": out, \"err\": err}\n",
    "\n",
    "for name in ctx:\n",
    "    res = run_this(name)\n",
    "    print(f\"{name}: {res['out']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a768fc2",
   "metadata": {},
   "source": [
    "# Service Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be4329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CONTEXTS=\"\"\"\n",
    "aws3\n",
    "aws4\n",
    "aws5\n",
    "aws6\n",
    "aws7\n",
    "aws8\n",
    "aws9\n",
    "aws10\n",
    "aws11\n",
    "aws12\n",
    "gcp1\n",
    "gcp2\n",
    "gcp3\n",
    "gcp4\n",
    "op1\n",
    "\"\"\"\n",
    "\n",
    "# FILE=\"/home/ubuntu/skycluster-project/skycluster-operator/examples/apps/air-quality/service-monitor.yaml\"\n",
    "FILE=\"/home/ubuntu/skycluster-project/skycluster-operator/examples/dev/prometheus/prometheus-scrape-config-remote.yaml\"\n",
    "ctx = [ln.strip() for ln in CONTEXTS.splitlines() if ln.strip()]\n",
    "\n",
    "def run_this(name):\n",
    "    cmd = (\n",
    "        f\"kubectl --context {name} apply -f {FILE} \"\n",
    "    )\n",
    "    try:\n",
    "        code, out, err = run_shell_command(cmd, kubeconfig_path=KUBECONFIG_PATH)\n",
    "    except Exception as e:\n",
    "        return {\"name\": name, \"code\": -1, \"out\": \"\", \"err\": str(e)}\n",
    "    return {\"name\": name, \"code\": code, \"out\": out, \"err\": err}\n",
    "\n",
    "for name in ctx:\n",
    "    res = run_this(name)\n",
    "    print(f\"{name}: {res}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
